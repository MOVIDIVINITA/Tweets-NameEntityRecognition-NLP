{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,012 news articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>en</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.com</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74¬∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>en</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy &amp; cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy &amp; our cookie ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  url  \\\n",
       "0                                              http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html   \n",
       "1  https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902   \n",
       "\n",
       "        date language  \\\n",
       "0 2021-06-13       en   \n",
       "1 2021-02-28       en   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0                                                   Jon W. Horton | Obituaries | kokomoperspective.com   \n",
       "1       Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0  Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74¬∞...  \n",
       "1      Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy & cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy & our cookie ...  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_path = 'https://storage.googleapis.com/msca-bdp-data-open/news/nlp_a_5_news.json'\n",
    "news_df = pd.read_json(news_path, orient='records', lines=True)\n",
    "\n",
    "print(f'Sample contains {news_df.shape[0]:,.0f} news articles')\n",
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,105 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1534565117614084096</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>Low Orbit Tourist üåçüì∑</td>\n",
       "      <td></td>\n",
       "      <td>Body &amp;amp; Assembly - Halewood - United Kingdom\\nüåç53.3504,-2.8352296,402m\\n\\nHalewood Body &amp;amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1534565743429394439</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>CompleteCar.ie</td>\n",
       "      <td>RT</td>\n",
       "      <td>Land Rover Ireland has announced that the new Range Rover Sport starts at ‚Ç¨114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang       date                  name retweeted  \\\n",
       "0  1534565117614084096   en 2022-06-08  Low Orbit Tourist üåçüì∑             \n",
       "1  1534565743429394439   en 2022-06-08        CompleteCar.ie        RT   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                       text  \n",
       "0  Body &amp; Assembly - Halewood - United Kingdom\\nüåç53.3504,-2.8352296,402m\\n\\nHalewood Body &amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt  \n",
       "1                                                                                                                                                               Land Rover Ireland has announced that the new Range Rover Sport starts at ‚Ç¨114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_path = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/nlp_a_5_tweets.json'\n",
    "tweets_df = pd.read_json(tweets_path, orient='records', lines=True)\n",
    "print(f'Sample contains {tweets_df.shape[0]:,.0f} tweets')\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Discarding Non English Results and keeping only relevant columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discard_en(df,col):\n",
    "    df = df[df[col]==\"en\"]\n",
    "    \n",
    "\n",
    "discard_en(news_df,\"language\")\n",
    "discard_en(tweets_df,\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[[\"title\",\"text\"]]\n",
    "tweets_df = tweets_df[[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Applying appropriate cleaning methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def cleaning(df,col):\n",
    "    #df[col] = df[col].apply(lambda x: [word for word in nltk.tokenize.word_tokenize(x) if len(word)>1])\n",
    "    #df[col] = df[col].apply(lambda x: [word for word in x if not word.isnumeric()])\n",
    "    #df[col] = df[col].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "    #df[col] = df[col].apply(lambda x: \" \".join([word for word in x]))\n",
    "    df[col] = df[col].str.strip()\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\||\\n|(@\\w+.*?)|(http\\w\\S+.*?)|(#\\w+)',' ',x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning(news_df,\"title\")\n",
    "cleaning(news_df,\"text\")\n",
    "cleaning(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only cleaned the text by removing the whitespaces, URLs and Email addresses. I did not remove the stopwords, did not convert text to lower case and did not remove punctuations because it would cause problems in identifying appropriate entities and also during the sentence segmentation process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding top company name using NER-NTLK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Without Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_nltk(df,col):\n",
    "    ORG=[]\n",
    "    for text in df[col]:\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))):\n",
    "            if hasattr(chunk,\"label\") and chunk.label()== 'ORGANIZATION':\n",
    "                ORG.extend([c for c in chunk])\n",
    "    \n",
    "    org_counts = {}\n",
    "    for org in ORG:\n",
    "        if org[0] in org_counts:\n",
    "            org_counts[org[0]] += 1\n",
    "        else:\n",
    "            org_counts[org[0]] = 1\n",
    "    \n",
    "    sorted_org = sorted(org_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_20_orgs = sorted_org[:20]\n",
    "    \n",
    "    return(top_20_orgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('News', 638),\n",
       " ('Star', 322),\n",
       " ('Online', 232),\n",
       " ('Mail', 228),\n",
       " ('Daily', 205),\n",
       " ('BMW', 111),\n",
       " ('Automotive', 106),\n",
       " ('Business', 101),\n",
       " ('Car', 101),\n",
       " ('Live', 97),\n",
       " ('Shropshire', 95),\n",
       " ('GMC', 86),\n",
       " ('Ontario', 84),\n",
       " ('UK', 77),\n",
       " ('Auto', 76),\n",
       " ('Volkswagen', 76),\n",
       " ('Express', 66),\n",
       " ('Land', 60),\n",
       " ('SUVs', 49),\n",
       " ('Rover', 48)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk(news_df,\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_sample = news_df.sample(n=1000,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LA', 1357),\n",
       " ('NYC', 1286),\n",
       " ('News', 1078),\n",
       " ('Princess', 1012),\n",
       " ('MailOnline', 925),\n",
       " ('Prince', 912),\n",
       " ('Kate', 893),\n",
       " ('VERY', 732),\n",
       " ('Queen', 626),\n",
       " ('UK', 623),\n",
       " ('Duke', 613),\n",
       " ('Royal', 599),\n",
       " ('Awards', 598),\n",
       " ('Of', 531),\n",
       " ('House', 517),\n",
       " ('US', 494),\n",
       " ('COVID', 482),\n",
       " ('Land', 458),\n",
       " ('THE', 431),\n",
       " ('Duchess', 429)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk(news_df_sample,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 3441),\n",
       " ('Rover', 2796),\n",
       " ('BMW', 394),\n",
       " ('Discovery', 393),\n",
       " ('Motors', 314),\n",
       " ('General', 300),\n",
       " ('Jaguar', 294),\n",
       " ('LAND', 261),\n",
       " ('eBay', 223),\n",
       " ('UK', 204),\n",
       " ('Duke', 192),\n",
       " ('Duchess', 171),\n",
       " ('SHAMELESS', 157),\n",
       " ('Defender', 146),\n",
       " ('SUV', 136),\n",
       " ('Range', 119),\n",
       " ('Services', 114),\n",
       " ('Health', 106),\n",
       " ('Invictus', 94),\n",
       " ('ROVER', 89)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. With Sentence Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tokenizer(df,col):\n",
    "    new_col_name = col + \"_sent_tokens\"\n",
    "    df[new_col_name] = df[col].apply(lambda x : nltk.tokenize.sent_tokenize(x))\n",
    "\n",
    "\n",
    "def ner_nltk_sent(df,col):\n",
    "    ORG=[]\n",
    "    for row in df[col]:\n",
    "        for token in row:\n",
    "            for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(token))):\n",
    "                if hasattr(chunk,\"label\") and chunk.label()== 'ORGANIZATION':\n",
    "                    ORG.extend([c for c in chunk])\n",
    "                    \n",
    "    org_counts = {}\n",
    "    for org in ORG:\n",
    "        if org[0] in org_counts:\n",
    "            org_counts[org[0]] += 1\n",
    "        else:\n",
    "            org_counts[org[0]] = 1\n",
    "    \n",
    "    sorted_org = sorted(org_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_20_orgs = sorted_org[:20]\n",
    "    \n",
    "    return(top_20_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer(news_df,\"title\")\n",
    "sent_tokenizer(news_df,\"text\")\n",
    "sent_tokenizer(news_df_sample,\"text\")\n",
    "sent_tokenizer(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('News', 638),\n",
       " ('Star', 322),\n",
       " ('Online', 232),\n",
       " ('Mail', 228),\n",
       " ('Daily', 205),\n",
       " ('BMW', 111),\n",
       " ('Automotive', 106),\n",
       " ('Business', 101),\n",
       " ('Car', 101),\n",
       " ('Live', 97),\n",
       " ('Shropshire', 95),\n",
       " ('GMC', 86),\n",
       " ('Ontario', 84),\n",
       " ('UK', 77),\n",
       " ('Auto', 76),\n",
       " ('Volkswagen', 76),\n",
       " ('Express', 66),\n",
       " ('Land', 60),\n",
       " ('SUVs', 49),\n",
       " ('Rover', 48)]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_sent(news_df,\"title_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LA', 1356),\n",
       " ('NYC', 1286),\n",
       " ('News', 1084),\n",
       " ('Princess', 1019),\n",
       " ('MailOnline', 925),\n",
       " ('Prince', 913),\n",
       " ('Kate', 868),\n",
       " ('VERY', 730),\n",
       " ('Queen', 627),\n",
       " ('UK', 623),\n",
       " ('Duke', 620),\n",
       " ('Royal', 600),\n",
       " ('Awards', 598),\n",
       " ('Of', 531),\n",
       " ('House', 523),\n",
       " ('US', 491),\n",
       " ('COVID', 483),\n",
       " ('Land', 465),\n",
       " ('Duchess', 416),\n",
       " ('Philip', 415)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_sent(news_df_sample,\"text_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 3448),\n",
       " ('Rover', 2846),\n",
       " ('Discovery', 394),\n",
       " ('BMW', 390),\n",
       " ('Motors', 314),\n",
       " ('Jaguar', 302),\n",
       " ('General', 300),\n",
       " ('LAND', 262),\n",
       " ('eBay', 223),\n",
       " ('UK', 204),\n",
       " ('Duke', 192),\n",
       " ('Duchess', 171),\n",
       " ('SHAMELESS', 157),\n",
       " ('Defender', 146),\n",
       " ('SUV', 136),\n",
       " ('Range', 119),\n",
       " ('Services', 114),\n",
       " ('Health', 106),\n",
       " ('Invictus', 94),\n",
       " ('ROVER', 90)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_sent(tweets_df,\"text_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tables, we can infer that the NER-NLTK model does not perform well as it identifies a lot of other things such as News, NYC, LA, Online and other words as Organizations which is not the case. \n",
    "\n",
    "However, for the tweets, it performs slightly better as it identifies companies such as Land Rover (but seperately), BMW and Jaguar. \n",
    "\n",
    "The results are also slightly better in the case of sentence segmentation as the model identifies more counts of company names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding top company name using NER SpaCy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Without Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_spacy(df,col):\n",
    "    entities=[]\n",
    "    labels=[]\n",
    "    for i in df[col]:\n",
    "        doc=nlp(i)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"ORG\":\n",
    "                entities.append(ent.text)\n",
    "                labels.append(ent.label_)\n",
    "    ent_df = pd.DataFrame({'Entities':entities,'Labels':labels})\n",
    "    ent_gpd = ent_df.groupby(\"Entities\").count().sort_values(by=\"Labels\",ascending=False).head(20)\n",
    "    \n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_spacy(df,col):\n",
    "    entities=[]\n",
    "    labels=[]\n",
    "    for doc in nlp.pipe(texts = df.loc[:,col], n_process = num_processors-5,batch_size=300):\n",
    "        for ent in doc:\n",
    "            if ent.ent_type_ == \"ORG\":\n",
    "                entities.append(ent.text)\n",
    "                labels.append(ent.ent_type_)\n",
    "    ent_df = pd.DataFrame({'Entities':entities,'Labels':labels})\n",
    "    ent_gpd = ent_df.groupby(\"Entities\").count().sort_values(by=\"Labels\",ascending=False).head(20)\n",
    "    \n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star</th>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auto</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Times</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Labels\n",
       "Entities          \n",
       "News           749\n",
       "-              619\n",
       "Star           439\n",
       "Ford           362\n",
       "&              229\n",
       "Hyundai        212\n",
       "Auto           206\n",
       "Daily          195\n",
       "Chevrolet      169\n",
       "Toyota         167\n",
       "Online         166\n",
       "The            163\n",
       "Honda          150\n",
       "Express        146\n",
       "Times          141\n",
       "Mercedes       139\n",
       "Automotive     130\n",
       "BMW            127\n",
       "Nissan         118\n",
       "               115"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy(news_df,\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 5.68 s, total: 33.1 s\n",
      "Wall time: 10min 52s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>3697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Royal</th>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MailOnline</th>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19</th>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/</th>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Awards</th>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mail</th>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Labels\n",
       "Entities                                                \n",
       "the                                                 3697\n",
       "&                                                   3301\n",
       "-                                                   2123\n",
       "'s                                                  1809\n",
       "The                                                 1490\n",
       "of                                                  1193\n",
       "'                                                   1183\n",
       "Royal                                                997\n",
       "News                                                 946\n",
       "MailOnline                                           925\n",
       "Ford                                                 862\n",
       "House                                                826\n",
       "COVID-19                                             681\n",
       "/                                                    680\n",
       "                             ¬†                       648\n",
       "Awards                                               570\n",
       "Toyota                                               550\n",
       "and                                                  548\n",
       "Mail                                                 547\n",
       "New                                                  479"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ner_spacy(news_df_sample,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Labels\n",
       "Entities                                               \n",
       "Land Rover                                         1041\n",
       "Jaguar Land Rover                                   940\n",
       "eBay                                                477\n",
       "BMW                                                 383\n",
       "General Motors                                      292\n",
       "Mercedes-Benz, Citroen                              285\n",
       "Jaguar                                              175\n",
       "Ford                                                116\n",
       "Audi                                                 99\n",
       "Volvo                                                93\n",
       "Tesla                                                88\n",
       "Bentley                                              76\n",
       "Jeep                                                 73\n",
       "Mercedes                                             68\n",
       "Mazda                                                66\n",
       "the Jaguar Land Rover Driving Challenge              66\n",
       "the SHAMELESS Health Services Board of Zimbabwe      64\n",
       "SHAMELESS                                            64\n",
       "Toyota                                               63\n",
       "VRM BR19                                             62"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. With Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_spacy_sent(df,col):\n",
    "    entities=[]\n",
    "    labels=[]\n",
    "    for row in df[col]:\n",
    "        for token in row:\n",
    "            doc=nlp(token)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"ORG\":\n",
    "                    entities.append(ent.text)\n",
    "                    labels.append(ent.label_)\n",
    "    ent_df = pd.DataFrame({'Entities':entities,'Labels':labels})\n",
    "    ent_gpd = ent_df.groupby(\"Entities\").count().sort_values(by=\"Labels\",ascending=False).head(20)\n",
    "    \n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star News</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnipeg Manitoba Carpages.ca</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto Ontario Carpages.ca</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive News</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoventryLive</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambridge Ontario Carpages.ca</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London Ontario Carpages.ca</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shropshire Star</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otago Daily Times Online News</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express Star</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Labels\n",
       "Entities                             \n",
       "Ford                              259\n",
       "Hyundai                           203\n",
       "Chevrolet                         164\n",
       "Toyota                            163\n",
       "Star News                         160\n",
       "Honda                             144\n",
       "Winnipeg Manitoba Carpages.ca     137\n",
       "Toronto Ontario Carpages.ca       113\n",
       "Automotive News                    98\n",
       "BMW                                98\n",
       "CoventryLive                       94\n",
       "RAM                                93\n",
       "Cambridge Ontario Carpages.ca      88\n",
       "London Ontario Carpages.ca         86\n",
       "Shropshire Star                    86\n",
       "Otago Daily Times Online News      70\n",
       "Express Star                       69\n",
       "Jeep                               67\n",
       "Nissan                             65\n",
       "EV                                 64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_sent(news_df,\"title_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MailOnline</th>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instagram</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palace</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britney Spears</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duke</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Labels\n",
       "Entities              \n",
       "MailOnline         925\n",
       "COVID-19           644\n",
       "Ford               643\n",
       "Toyota             527\n",
       "Instagram          406\n",
       "Hyundai            400\n",
       "Honda              390\n",
       "Trump              378\n",
       "BMW                375\n",
       "Amazon             366\n",
       "Netflix            347\n",
       "EV                 329\n",
       "COVID              312\n",
       "Palace             300\n",
       "House              282\n",
       "Britney Spears     264\n",
       "Duke               232\n",
       "Apple              225\n",
       "BBC                222\n",
       "Nissan             221"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_sent(news_df_sample,\"text_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Labels\n",
       "Entities                                               \n",
       "Land Rover                                         1041\n",
       "Jaguar Land Rover                                   951\n",
       "eBay                                                477\n",
       "BMW                                                 383\n",
       "General Motors                                      292\n",
       "Mercedes-Benz, Citroen                              285\n",
       "Jaguar                                              168\n",
       "Ford                                                116\n",
       "Audi                                                100\n",
       "Volvo                                                94\n",
       "Tesla                                                88\n",
       "Bentley                                              76\n",
       "Jeep                                                 73\n",
       "Mercedes                                             68\n",
       "the Jaguar Land Rover Driving Challenge              66\n",
       "Mazda                                                66\n",
       "SHAMELESS                                            64\n",
       "the SHAMELESS Health Services Board of Zimbabwe      64\n",
       "Toyota                                               63\n",
       "VRM BR19                                             62"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_sent(tweets_df,\"text_sent_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the SpaCy model performs very well when compared to the NER-NLTK model as it correctly identifies the company names with a few exceptions. We can also see that the model with sentence segmentation performs better than the one where only word tokenizaton is done. This is because in the sentence segmention, the model correctly identifies the context in more cases. \n",
    "\n",
    "**For the titles in news articles, the most frequently mentioned company is Ford and other companies that are mentioned along with Ford are Hyundai, Chevrolet, Toyota and Honda.**\n",
    "\n",
    "**For the text in news articles, the most frequently mentioned company is Ford and other companies that are mentioned along with Ford are Toyota, Hyundia, Honda and BMW.**\n",
    "\n",
    "**For the tweets, the most frequently mentioned company is Land Rover and other companies that are mentioned along with Land Rover are Jaquar, BMW, General Motors, Mercedez-Benz and Ford.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding top Locations using NER NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_nltk_loc(df,col):\n",
    "    LOC=[]\n",
    "    for text in df[col]:\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))):\n",
    "            if hasattr(chunk,\"label\") and chunk.label()== 'GPE':\n",
    "                LOC.extend([c for c in chunk])\n",
    "    \n",
    "    loc_counts = {}\n",
    "    for loc in LOC:\n",
    "        if loc[0] in loc_counts:\n",
    "            loc_counts[loc[0]] += 1\n",
    "        else:\n",
    "            loc_counts[loc[0]] = 1\n",
    "    \n",
    "    sorted_loc = sorted(loc_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_20_locs = sorted_loc[:20]\n",
    "    \n",
    "    return(top_20_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sale', 1966),\n",
       " ('British', 195),\n",
       " ('New', 180),\n",
       " ('Prince', 157),\n",
       " ('Winnipeg', 137),\n",
       " ('India', 121),\n",
       " ('Toronto', 118),\n",
       " ('London', 112),\n",
       " ('North', 111),\n",
       " ('China', 108),\n",
       " ('York', 99),\n",
       " ('Cambridge', 91),\n",
       " ('Calgary', 63),\n",
       " ('U.S.', 63),\n",
       " ('Taiwan', 56),\n",
       " ('Mississauga', 55),\n",
       " ('Land', 53),\n",
       " ('Kitchener', 45),\n",
       " ('Oakville', 42),\n",
       " ('Innisfil', 41)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(news_df,\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('New', 2103),\n",
       " ('York', 1571),\n",
       " ('London', 1198),\n",
       " ('Los', 1128),\n",
       " ('Angeles', 1044),\n",
       " ('City', 944),\n",
       " ('British', 794),\n",
       " ('West', 701),\n",
       " ('India', 533),\n",
       " ('Prince', 517),\n",
       " ('South', 427),\n",
       " ('Miami', 425),\n",
       " ('Australia', 419),\n",
       " ('California', 412),\n",
       " ('Mexico', 389),\n",
       " ('China', 386),\n",
       " ('American', 380),\n",
       " ('Malibu', 378),\n",
       " ('U.S.', 363),\n",
       " ('Hollywood', 360)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(news_df_sample,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Land', 1562),\n",
       " ('Russia', 180),\n",
       " ('British', 156),\n",
       " ('New', 140),\n",
       " ('Jaguar', 128),\n",
       " ('Sussex', 120),\n",
       " ('India', 92),\n",
       " ('Zimbabwe', 86),\n",
       " ('Ad', 83),\n",
       " ('Russian', 77),\n",
       " ('Audi', 70),\n",
       " ('Car', 69),\n",
       " ('Cambridge', 68),\n",
       " ('Britain', 64),\n",
       " ('Meghan', 64),\n",
       " ('Paracetamol', 64),\n",
       " ('LAND', 63),\n",
       " ('UPDATE', 54),\n",
       " ('Indian', 53),\n",
       " ('Netherlands', 52)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_nltk_loc(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding top Locations using NER SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_spacy_loc(df,col):\n",
    "    entities=[]\n",
    "    labels=[]\n",
    "    for i in df[col]:\n",
    "        doc=nlp(i)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"GPE\":\n",
    "                entities.append(ent.text)\n",
    "                labels.append(ent.label_)\n",
    "    ent_df = pd.DataFrame({'Entities':entities,'Labels':labels})\n",
    "    ent_gpd = ent_df.groupby(\"Entities\").count().sort_values(by=\"Labels\",ascending=False).head(20)\n",
    "    \n",
    "    return ent_gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Title)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alberta</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calgary</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North York</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S.</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbia</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vancouver</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Labels\n",
       "Entities          \n",
       "UK             179\n",
       "India           94\n",
       "US              85\n",
       "Alberta         68\n",
       "Calgary         64\n",
       "North York      59\n",
       "U.S.            58\n",
       "Taiwan          53\n",
       "China           52\n",
       "Russia          42\n",
       "Britain         40\n",
       "Columbia        39\n",
       "Australia       34\n",
       "Ukraine         32\n",
       "Texas           21\n",
       "Vancouver       21\n",
       "England         21\n",
       "California      20\n",
       "London          20\n",
       "British         19"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_loc(news_df,\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **News Articles (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hollywood</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meghan</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Hollywood</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beverly Hills</th>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney</th>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malibu</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Labels\n",
       "Entities              \n",
       "LA                1872\n",
       "London            1258\n",
       "UK                1221\n",
       "US                1039\n",
       "Los Angeles        997\n",
       "New York City      739\n",
       "Hollywood          595\n",
       "India              550\n",
       "Miami              476\n",
       "Meghan             475\n",
       "New York           467\n",
       "Australia          463\n",
       "California         437\n",
       "West Hollywood     432\n",
       "Beverly Hills      423\n",
       "Sydney             419\n",
       "China              383\n",
       "Britain            370\n",
       "Mexico             366\n",
       "Malibu             354"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_loc(news_df_sample,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meghan</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kibaki</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jamaica</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üí∏</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hague</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridgwater</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hollywood</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nyeri</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Labels\n",
       "Entities            \n",
       "UK               342\n",
       "Russia           184\n",
       "India             95\n",
       "Meghan            78\n",
       "Kibaki            76\n",
       "Britain           69\n",
       "Jamaica           59\n",
       "Netherlands       45\n",
       "üí∏                 42\n",
       "Zimbabwe          41\n",
       "The Hague         40\n",
       "London            36\n",
       "China             36\n",
       "South Africa      35\n",
       "Bridgwater        26\n",
       "New Zealand       25\n",
       "France            25\n",
       "US                25\n",
       "Hollywood         24\n",
       "Nyeri             23"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_spacy_loc(tweets_df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the NER-SpaCy model performs much better than the NER-NLTK model in identifying locations. The NER-NLK model falsly identifies a lot of entities. For eg: it identifies \"Land\" as a location but in reality it refers to Land Rover which is a company. Similarly, it has a few other entities which are falsly identified. Whereas, the SpaCy model identifies locations correctly which very few exceptions. \n",
    "\n",
    "**For Titles in News Articles, the most frequenctly mentioned location is UK followed by India, US and Alberta.**\n",
    "\n",
    "**For Text in News Articles, the most frequenctly mentioned location is LA followed by London,UK and US.**\n",
    "\n",
    "**For the tweets, the most frequenctly mentioned location is UK followed by Russia, India and Britain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Top-20 List of the best performing model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. For Company Name : NER SpaCy Model with Segmentation provides best results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">News Articles(Title)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star News</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnipeg Manitoba Carpages.ca</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto Ontario Carpages.ca</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive News</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoventryLive</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambridge Ontario Carpages.ca</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London Ontario Carpages.ca</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shropshire Star</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otago Daily Times Online News</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express Star</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">News Articles(Text)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MailOnline</th>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID-19</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instagram</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVID</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palace</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britney Spears</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duke</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Tweets</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Land Rover</th>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar Land Rover</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eBay</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz, Citroen</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Jaguar Land Rover Driving Challenge</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAMELESS</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the SHAMELESS Health Services Board of Zimbabwe</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRM BR19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side(ner_spacy_sent(news_df,\"title_sent_tokens\"),ner_spacy_sent(news_df_sample,\"text_sent_tokens\")\n",
    "                     ,ner_spacy_sent(tweets_df,\"text_sent_tokens\")\n",
    "                     , titles=['News Articles(Title)','News Articles(Text)','Tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the titles in news articles, the most frequently mentioned company is Ford and other companies that are mentioned along with Ford are Hyundai, Chevrolet, Toyota and Honda.**\n",
    "\n",
    "**For the text in news articles, the most frequently mentioned company is Ford and other companies that are mentioned along with Ford are Toyota, Hyundia, Honda and BMW.**\n",
    "\n",
    "**For the tweets, the most frequently mentioned company is Land Rover and other companies that are mentioned along with Land Rover are Jaquar, BMW, General Motors, Mercedez-Benz and Ford.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. For Location : NER SpaCy Model provides best results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">News Articles(Title)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alberta</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calgary</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North York</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S.</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbia</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vancouver</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">News Articles(Text)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City</th>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hollywood</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meghan</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Hollywood</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beverly Hills</th>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney</th>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malibu</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Tweets</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entities</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meghan</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kibaki</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Britain</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jamaica</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üí∏</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hague</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridgwater</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hollywood</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nyeri</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side(ner_spacy_loc(news_df,\"title\"),ner_spacy_loc(news_df_sample,\"text\"),\n",
    "                     ner_spacy_loc(tweets_df,\"text\"), titles=['News Articles(Title)','News Articles(Text)','Tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Titles in News Articles, the most frequenctly mentioned location is UK followed by India, US and Alberta.**\n",
    "\n",
    "**For Text in News Articles, the most frequenctly mentioned location is LA followed by London,UK and US.**\n",
    "\n",
    "**For the tweets, the most frequenctly mentioned location is UK followed by Russia, India and Britain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
